# Bags of Words

When we read, our eyes move in sequence across the page and take in phrase after phrase in the order in which they were intended. This sense of chronology integral to how we, as human readers, understand texts. But it is possible to imagine other ways of reading. Have you ever skimmed over a page backwards looking at every other word? You probably still got the gist of the text even though you 


Our previous examples have preserved this sense of time - when we counted words with *Voyant*, we then graphed them over time. 
Topic modeling 

not dependent on location - just looking at all the different words that show up in a document.

The topic modeling algorithm looks for statistically significant clusters of words. 
The output of a

unsupervised classifier